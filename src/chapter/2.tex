% ============================================== %
%
% Dataset Analysis Chapter
%
%% ============================================== %
\hypersetup{colorlinks=true, linkcolor=blue, citecolor=red}
\chapter{Dataset analysis} \label{chap:dataset_analysis}
    %? Descrizione generale di cosa contiene il capitolo.
    In this chapter, the dataset used in this thesis is analyzed. The data collection methodology is described, along with the recording setup. The data structure and attributes are presented, along with the participants characteristics. Finally, the data processing steps are described.

    \section{Data collection methodology}
        %? Riassunto di cosa è stato fatto per raccogliere i dati.
        Data used in this thesis was collected at the Waterford Hospital in Ireland as part of a Fear of Falling study conducted on a group of 22 elderly individuals.  A Microsoft Kinect sensor was used to record the movements performed following a recording setup. 
        \subsection{Microsoft kinect}
                    \subsubsection{Kinect sensor} 

                    \subsubsection{Kinect skeletal tracking}
        \newpage

        \subsection{Recording setup}

                    The patient's data recording setup illustrated in Figure \ref{fig:kinect_setup} consists of consumer-level hardware (a laptop, a Kinect v2 depth camera, an external webcam, and a smartphone) and a dedicated application developed within the project. 
                    Once launched, the operator can display a sample stimulus on an external monitor to show the target movements to the patient (\textit{1. Stimulus playback}) so they can repeat (\textit{2. patient performs movement}) them by selecting one of them from a list in the appplication.
                    Then, by pressing the "\textit{record}" button (\textit{3. record/analyse skeleton + rgb + accelerometer}), the recording of the patient's full-body movement can be started. 
                    The application stores the recorded patient's movement files in a separate folders, naming them based on their patient ID, movement ID, and repetition ID.

                    \begin{figure}[H]
                        \centering
                        \includegraphics[width=1.0\textwidth]{./resources/kinect/setup.png}
                        \caption{Kinect recording setup.}
                        \label{fig:kinect_setup}
                    \end{figure}
                    
                    The full-body capture mainly relies on the PyKinect library \cite{GitHubKinectPyKinect2}.
                    The library provides functions for getting the patient's body segment's position and rotation 25 times per second. The application gets the data and stores it as a multi-dimensional time series (one per body segment and coordinate type) in CSV files like the one shown in Figure \ref{fig:csv_structure}.

                    \begin{figure}[H]
                        \centering
                        \includegraphics[width=1.0\textwidth]{./resources/other/data.png}
                        \caption{Example of a CSV file containing the Kinect skeleton data.}
                        \label{fig:csv_structure}
                    \end{figure}

                    The accelerometer is captured via a smartphone running an app streaming 3D gyroscope data at 50 frames per second. Again, the application on the computer stores it as a multi-dimensional time series (one per rotation axis). The communication between the smartphone and the computer is based on a wireless network and the Open Sound Control (OSC) protocol \cite{wright_open_nodate}.
    
    \section{Data structure and attributes}
            
            Data used in this thesis consists of a series of CSV files, each containing 3D coordinates of the joints of a participant performing a movement. The total number of csv files is \textbf{637}. In Figure \ref{fig:dataset_files} the distribution of the csv files between the movements is presented with a median of \textbf{68} files per movement.

            \begin{figure}[H]
                \centering 
                \includegraphics[width=1.0\textwidth]{./resources/other/csv-files-mov.png}
                \caption{CSV files distribution between the movements. \textit{M009} is the only movement with less than 68 files due to it not being performed multiple times by the participants.}
                \label{fig:dataset_files}
            \end{figure}
        
            Dataset is organized in a directory structure. Each patient has a folder named with their ID (\textit{Patient-ID}) and inside there are 10 folders for each movement, named with the movement ID (\textit{M-XXX}). For every movement folder there is a folder for each repetition of the movement, named with the repetition ID (\textit{R-XXX}). Inside each repetition folder there is a CSV file that contains the Kinect skeleton data. In Figure \ref{fig:directory-structure} an example of the directory structure is displayed. \\
            
            \begin{figure}[htbp]
                \centering
                \begin{forest}
                for tree={
                folder,
                grow'=0,
                fit=band,
                }
                [Patients
                    [Patient-1
                        [M000
                            [R000
                                [FILE.CSV]
                            ]
                            [R001]
                            [R002]
                        ]
                    ]
                ]
                \end{forest}
                \caption{Directory structure example using the first patient and first movement in the dataset. }
                \label{fig:directory-structure}
            \end{figure}

            a CSV file is organized as a series of columns, each column represent a joint in Table \ref{tab:joints_recorded} that the Kinect sensor records. Each joint is represented by 4 columns, one for each coordinate (x, y, z) and one for the state. The state column is used to indicate if the joint is trackd or not. Beside the joints columns, there are 2 columns for the timestamp and datetime of the recording.
            
            \begin{table}[H]
                \centering
                \caption{Joints recorded by the Kinect sensor.}
                \label{tab:joints_recorded}
                \begin{tabularx}{1.0\textwidth}{XXXX} 
                    \toprule
                    \multicolumn{4}{c}{\textbf{Joints}} \\ 
                    \midrule
                    AnkleLeft & AnkleRight & ElbowLeft & ElbowRight \\
                    FootLeft & FootRight & HandLeft & HandRight \\ 
                    HandTipLeft & HandTipRight & Head & HipLeft \\
                    HipRight & KneeLeft & KneeRight & Neck \\
                    ShoulderLeft & ShoulderRight & SpineBase & SpineMid \\ 
                    SpineShoulder & ThumbLeft & ThumbRight & WristLeft \\
                    WristRight & & & \\
                    \bottomrule
                \end{tabularx}
            \end{table}

     \newpage

    \section{Participants characteristics}
        The participants that took part in the study were 22 elderly individuals, in Figure \ref{fig:age_distribution} the age distribution of the patients is presented, with a median age of 67 years. 
        \begin{figure}[H]
            \centering
            \includegraphics[width=1.0\textwidth]{./resources/other/patients-age.png}
            \caption{Age distribution of the participants.}
            \label{fig:age_distribution}
        \end{figure}

        In Figure \ref{fig:patients_characteristics} patients characteristics are presented. Fear of Falling is present in \textbf{57\%} of the patients, this is a relatively high percentage, due to the study being conducted on a Fear of Falling assessment group. The patients gender is dominated by females with a \textbf{95\%} of the patients, this is also expected since most studies in the literature had mostly female participants (>50\%) \cite{mackay_fear_2021}. The patients education is also presented, with the majority of the patients having a \textbf{Secondary} or \textbf{Third Level} education.
        \begin{figure}[H]
            \centering
            \includegraphics[width=1.0\textwidth]{./resources/other/patients-char.png}
            \caption{Age distribution of the participants.}
            \label{fig:patients_characteristics}
        \end{figure}

        \subsubsection{What is fear of falling ?}
        
            The definition of \textbf{Fear of Falling} had various interpretations over the years. Initially, it was described as a phobic reaction to standing or walking. However, it was reclassified as a syndrome characterzied by the aftermath of a fall. As understanding developed, this fear was seen as a loss of confidence in one's balance ability. It was also further defined as an ongoing concern about falling, which leads to the avoidance of performing daily activities. Recently, it has been described as continous avoidance of activities due to the concern of falling. \cite{jung_fear_2008}
    
    \section{Movements visualization} \label{sec:movements_visualization}
        %! Transformazione dei dati in un formato che può essere visualizzato.
        Kinect-based data comes as a series of 3D coordinates, which can be visualized in 3D space. In this section, the implementation of the movements visualization is described. The visualization was implemented using the Python programming language and the Plotly library \cite{plotly}.

        The first step in the visualization process is to identify the set of joints to be used. In this approach, the dataset contains 25 joints but only 16 joints are used and are shown in Table \ref{tab:joints_selected}. 

        \begin{table}[h]
            \centering
            \caption{Selected kinect joints used for the visualization.}
            \label{tab:joints_selected}
            \begin{tabularx}{0.8\textwidth}{XXX}
                \toprule
                \multicolumn{3}{c}{\textbf{Joints}} \\
                \midrule
                Head & Spine Shoulder & Spine Mid \\
                Spine Base & Shoulder Right & Elbow Right \\
                Wrist Right & Shoulder Left & Elbow Left \\
                Wrist Left & Hip Right & Knee Right \\
                Ankle Right & Hip Left & Knee Left \\
                Ankle Left & & \\
                \bottomrule
            \end{tabularx}
        \end{table}
        The selected joints form toghether a skeleton, which is shown in Figure \ref{fig:kinect_skeleton}. The skeleton is used to visualize the movements performed by the participants. \\

        Once the joints are selected, the next step is to transform the data. In its original state the data is organized incorrectly for the 3D visualization, the y and z coordinates are inverted. To fix this, the y and z coordinates are swapped. The data is then transformed into a Pandas DataFrame, which is then used to create the 3D visualization. \\

        \newpage

        \begin{lstlisting}[caption={Traditional approach to splitting the data into training and testing sets.}, label={lst:badsplit}]            
            for index, row in data_transformed.iterrows():
                x_values = [row[f"{joint}.px"] for joint in joints]
                y_values = [row[f"{joint}.py"] for joint in joints]
                z_values = [row[f"{joint}.pz"] for joint in joints]
                lines = []
                for connection in connections:
                    start, end = connection
                    lines.append(
                        go.Scatter3d(
                            x=[row[f"{start}.px"], row[f"{end}.px"]],
                            y=[row[f"{start}.py"], row[f"{end}.py"]],
                            z=[row[f"{start}.pz"], row[f"{end}.pz"]],
                        )
                    )
        \end{lstlisting}

        \begin{figure}[h]
            \begin{subfigure}{.5\textwidth}
                \centering
                \includegraphics[width=.9\linewidth]{../src/resources/mov-plots/mov-0.png}
                \caption{Chair to Chair}
                \label{fig:mov-0}
            \end{subfigure}
            \begin{subfigure}{.5\textwidth}
                \centering
                \includegraphics[width=.9\linewidth]{../src/resources/mov-plots/mov-1.png}
                \caption{Hoop Walk}
                \label{fig:mov-1}
            \end{subfigure}
            
            \begin{subfigure}{.5\textwidth}
                \centering
                \includegraphics[width=.9\linewidth]{../src/resources/mov-plots/mov-2.png}
                \caption{Cross Reach Left}
                \label{fig:mov-2}
            \end{subfigure}
            \begin{subfigure}{.5\textwidth}
                \centering
                \includegraphics[width=.9\linewidth]{../src/resources/mov-plots/mov-9.png}
                \caption{Tug Walk}
                \label{fig:mov-9}
            \end{subfigure}
            
            \caption{Main caption}
            \label{fig:movements_visualization}
        \end{figure}

        In Figure \ref{fig:movements_visualization} some of the movements performed by the participants are shown. The movements are shown in 3D, with the x, y, and z axes representing the coordinates of the joints. 
    \section{Data processing}

        Original dataset containing the Kinect skeleton data was processed to remove noise and outliers. This process is needed to improve the classification results. The data processing steps are described in the following sections.
        
        \subsection{Cleaning}
        
        From the original dataset a process of cleaning the data was performed. Consisting of removing the columns that contained zero values and the ones that were not needed for the classification task. The columns that were kept are listed in the Table \ref{tab:joints_selected}, only the positional coordinates were kept, the state columns and rotation columns (x, y, z) were removed due to not giving any useful information for the classification task.

        \subsection{Normalization}

        Pose normalization was performed using the formula described in \cite{maudsley-barton_comparative_2017} as follow:
        \begin{equation}
            P_{n,i}(x,y,z) = P_{n,i}(x,y,z)-P_{spinebase,1}(x,y,z)
            \label{eq:pose_normalization}
        \end{equation}

        Equation \ref{eq:pose_normalization} is used to normalize the pose of a participant performing a movement. The pose is normalized by subtracting the coordinates of the Spine Base joint in the first frame from the coordinates of all the joints in the dataframe. This is done to remove the effect of the position of the participant in the recording setup and align all the frames to the same position. 

        \subsection{Transformation}

        Once the data cleaning and normalization was performed, the data was transformed into a format that can used for a classification task. The data was transformed using the scikit-learn library \cite{sklearn_api}, \textbf{MinMaxScaler} was used to scale the data between 0 and 1 then \textbf{StandardScaler} was used to standardize the data. After this process the data was ready to be used for a Machine Learning model.

\cleardoublepage