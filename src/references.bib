@article{scikit-learn,
 title={Scikit-learn: Machine Learning in {P}ython},
 author={Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V.
         and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P.
         and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and
         Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
 journal={Journal of Machine Learning Research},
 volume={12},
 pages={2825--2830},
 year={2011}
}

@inproceedings{sklearn_api,
  author    = {Lars Buitinck and Gilles Louppe and Mathieu Blondel and
               Fabian Pedregosa and Andreas Mueller and Olivier Grisel and
               Vlad Niculae and Peter Prettenhofer and Alexandre Gramfort
               and Jaques Grobler and Robert Layton and Jake VanderPlas and
               Arnaud Joly and Brian Holt and Ga{\"{e}}l Varoquaux},
  title     = {{API} design for machine learning software: experiences from the scikit-learn
               project},
  booktitle = {ECML PKDD Workshop: Languages for Data Mining and Machine Learning},
  year      = {2013},
  pages = {108--122},
}

@book{jana_kinect_2012,
	edition = {1},
	title = {Kinect for {Windows} {SDK} {Programming} {Guide}},
	isbn = {978-1-84969-238-0},
	url = {https://www.perlego.com/book/389793/kinect-for-windows-sdk-programming-guide-pdf},
	abstract = {In DetailKinect has been a game-changer in the world of motion games and applications since its first release. It has been touted as a controller for Microsoft Xbox but is much more than that. The developer version of Kinect, Kinect for Windows SDK, provides developers with the tools to develop applications that run on Windows. You can use this to develop applications that make interaction with your computer hands-free. 

  This book focuses on developing applications using the Kinect for Windows SDK. It is a complete end to end solution using different features of Kinect for Windows SDK with step by step guidance. The book will also help you develop motion sensitive and speech recognition enabled applications. You will also learn about building application using multiple Kinects.

  The book begins with explaining the different components of Kinect and then moves into to the setting up the device and getting thedevelopment environment ready. You will be surprised at how quickly the book takes you through the details of Kinect APIs. You will use NUI to use the Kinect for Natural Inputs like skeleton tracking, sensing, speech recognizing. 

  You will capture different types of stream, and images, handle stream event, and capture frame. Kinect device contains a motorized tilt to control sensor angles, you will learn how to adjust it automatically. The last part of the book teaches you how to build application using multiple Kinects and discuss how Kinect can be used to integrate with other devices such as Windows Phone and microcontroller.

  ApproachThis book is a practical tutorial that explains different features of Kinect for Windows SDK by creating sample applications throughout the book

  Who this book is forThe purpose of this book is to explain how to develop applications using the Kinect for Windows SDK. If you are a beginner and looking to start developing applications using the Kinect for Windows SDK, and if you want to build motion-sensing,speech-recognizing applications with Kinect, this book is for you.

  This book uses C\# and WPF (Windows Presentation Foundation) in the examples, so you need to know the basics of C\# and WPF. You should be familiar with the Visual Studio IDE as well. You don't have to know anything about the Kinect for Windows SDK.},
    language = {English},
    urldate = {2024-01-27},
    publisher = {Packt Publishing},
    author = {Jana, Abhijit},
    month = dec,
    year = {2012},
    keywords = {Computer Science, Digital Media},
}

@online{plotly, 
  author = {Plotly Technologies Inc.}, title = {Collaborative data science}, publisher = {Plotly Technologies Inc.}, address = {Montreal, QC}, year = {2015}, url = {https://plot.ly} 
}

@article{jung_fear_2008,
	title = {Fear of {Falling} in {Older} {Adults}: {Comprehensive} {Review}},
	volume = {2},
	issn = {19761317},
	shorttitle = {Fear of {Falling} in {Older} {Adults}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1976131709600037},
	doi = {10.1016/S1976-1317(09)60003-7},
	language = {en},
	number = {4},
	urldate = {2023-11-12},
	journal = {Asian Nursing Research},
	author = {Jung, Dukyoo},
	month = dec,
	year = {2008},
	pages = {214--222},
	annote = {Very important for the literature review, since it covers the definition of FoF and the methods to measure it.},
}

@article{mackay_fear_2021,
	title = {Fear of {Falling} in {Older} {Adults}: {A} {Scoping} {Review} of {Recent} {Literature}},
	volume = {24},
	issn = {1925-8348},
	shorttitle = {Fear of {Falling} in {Older} {Adults}},
	doi = {10.5770/cgj.24.521},
	abstract = {BACKGROUND: Fear of falling (FOF) is prevalent among older adults and associated with adverse health outcomes. Over recent years a substantial body of research has emerged on its epidemiology, associated factors, and consequences. This scoping review summarizes the FOF literature published between April 2015 and March 2020 in order to inform current practice and identify gaps in the literature.
  METHODS: A total of 439 articles related to FOF in older adults were identified, 56 selected for full-text review, and 46 retained for data extraction and synthesis.
  RESULTS: The majority of included studies were cross-sectional. Older age, female sex, previous falls, worse physical performance, and depressive symptoms were the factors most consistently associated with FOF. Studies that measured FOF with a single question reported a significantly lower prevalence of FOF than those using the Falls Efficacy Scale, a continuous measure. FOF was associated with higher likelihoods of future falls, short-term mortality, and functional decline.
  CONCLUSIONS: Comparisons between studies were limited by inconsistent definition and measurement of FOF, falls, and other characteristics. Consensus on how to measure FOF and which participant characteristics to evaluate would address this issue. Gaps in the literature include clarifying the relationships between FOF and cognitive, psychological, social, and environmental factors.},
	language = {eng},
	number = {4},
	journal = {Canadian geriatrics journal: CGJ},
	author = {MacKay, Scott and Ebert, Patricia and Harbidge, Cathy and Hogan, David B.},
	month = dec,
	year = {2021},
	pmid = {34912493},
	pmcid = {PMC8629501},
	keywords = {falls, fear of falling, older adults, scoping review},
	pages = {379--394},
	file = {Full Text:/Users/lucian/Zotero/storage/MJT9JDAG/MacKay et al. - 2021 - Fear of Falling in Older Adults A Scoping Review .pdf:application/pdf},
}

@inproceedings{maudsley-barton_comparative_2017,
	title = {A comparative study of the clinical use of motion analysis from {Kinect} skeleton data},
	url = {https://ieeexplore.ieee.org/abstract/document/8123052},
	doi = {10.1109/SMC.2017.8123052},
	abstract = {The analysis of human motion as a clinical tool can bring many benefits such as the early detection of disease and the monitoring of recovery, so in turn helping people to lead independent lives. However, it is currently under used. Developments in depth cameras, such as Kinect, have opened up the use of motion analysis in settings such as GP surgeries, care homes and private homes. To provide an insight into the use of Kinect in the healthcare domain, we present a review of the current state of the art. We then propose a method that can represent human motions from time-series data of arbitrary length, as a single vector. Finally, we demonstrate the utility of this method by extracting a set of clinically significant features and using them to detect the age related changes in the motions of a set of 54 individuals, with a high degree of certainty (F1-score between 0.9-1.0). Indicating its potential application in the detection of a range of age-related motion impairments.},
	urldate = {2023-12-07},
	booktitle = {2017 {IEEE} {International} {Conference} on {Systems}, {Man}, and {Cybernetics} ({SMC})},
	author = {Maudsley-Barton, Sean and McPhee, Jamie and Bukowski, Anthony and Leightley, Daniel and Yap, Moi Hoon},
	month = oct,
	year = {2017},
	pages = {2808--2813},
	file = {Accepted Version:/Users/lucian/Zotero/storage/6QP322X4/Maudsley-Barton et al. - 2017 - A comparative study of the clinical use of motion .pdf:application/pdf;IEEE Xplore Abstract Record:/Users/lucian/Zotero/storage/AQVGGDBL/8123052.html:text/html},
}

@inproceedings{choubik_machine_2016,
	title = {Machine {Learning} for {Real} {Time} {Poses} {Classification} {Using} {Kinect} {Skeleton} {Data}},
	url = {https://ieeexplore.ieee.org/abstract/document/7467728},
	doi = {10.1109/CGiV.2016.66},
	abstract = {Poses recognition is an important research topic because some situations require silent communication (sign language, surgeon poses to the nurse for assistance etc.). Traditionally, poses recognition requires high quality expensive cameras and complicated computer vision algorithms. This is not the case thanks to the Microsoft Kinect sensor which provides an inexpensive and easy way for real time user interaction. In this paper, we proposed a real time human poses classification technique, by using skeleton data provided by the Kinect sensor. Different users performed a set of tasks from a vocabulary of eighteen poses. From skeleton data of each pose, twenty features are extracted so that they are invariant with respect to the user's size and its position in the scene. We then compared the generalization performances of four machine learning algorithms, support vectors machines (SVM), artificial neural networks (ANN), k-nearest neighbors (KNN) and Bayes classifier (BC). The method used in this work shows that SVM outperforms the other algorithms.},
	urldate = {2023-12-07},
	booktitle = {2016 13th {International} {Conference} on {Computer} {Graphics}, {Imaging} and {Visualization} ({CGiV})},
	author = {Choubik, Youness and Mahmoudi, Abdelhak},
	month = mar,
	year = {2016},
	pages = {307--311},
	file = {Choubik and Mahmoudi - 2016 - Machine Learning for Real Time Poses Classificatio.pdf:/Users/lucian/Zotero/storage/RBI6K5HW/Choubik and Mahmoudi - 2016 - Machine Learning for Real Time Poses Classificatio.pdf:application/pdf;IEEE Xplore Abstract Record:/Users/lucian/Zotero/storage/D4CB48X5/7467728.html:text/html},
}

@misc{GitHubKinectPyKinect2,
	author = {},
	title = {{G}it{H}ub - {K}inect/{P}y{K}inect2: {W}rapper to expose {K}inect for {W}indows v2 {A}{P}{I} in {P}ython --- github.com},
	howpublished = {\url{https://github.com/Kinect/PyKinect2}},
	year = {},
}

@article{wright_open_nodate,
	title = {Open {SoundControl}: {A} {New} {Protocol} for {Communicating} with {Sound} {Synthesizers}},
	abstract = {Open SoundControl is a new protocol for communication among computers, sound synthesizers, and other multimedia devices that is optimized for modern networking technology. Entities within a system are addressed individually by an open-ended URL-style symbolic naming scheme that includes a powerful pattern matching language to specify multiple recipients of a single message. We provide high resolution time tags and a mechanism for specifying groups of messages whose effects are to occur simultaneously. There is also a mechanism for dynamically querying an Open SoundControl system to find out its capabilities and documentation of its features.},
	language = {en},
	author = {Wright, Matthew and Freed, Adrian},
	file = {Wright and Freed - Open SoundControl A New Protocol for Communicatin.pdf:/Users/lucian/Zotero/storage/TCJRGWUQ/Wright and Freed - Open SoundControl A New Protocol for Communicatin.pdf:application/pdf},
}

@article{zhang_microsoft_2012,
	title = {Microsoft {Kinect} {Sensor} and {Its} {Effect}},
	volume = {19},
	issn = {1070-986X},
	url = {http://ieeexplore.ieee.org/document/6190806/},
	doi = {10.1109/MMUL.2012.24},
	language = {en},
	number = {2},
	urldate = {2024-01-27},
	journal = {IEEE Multimedia},
	author = {Zhang, Zhengyou},
	month = feb,
	year = {2012},
	pages = {4--10},
	file = {Zhang - 2012 - Microsoft Kinect Sensor and Its Effect.pdf:/Users/lucian/Zotero/storage/EQW4BGLG/Zhang - 2012 - Microsoft Kinect Sensor and Its Effect.pdf:application/pdf},
}

@article{bentejac_comparative_2021,
	title = {A comparative analysis of gradient boosting algorithms},
	volume = {54},
	issn = {1573-7462},
	url = {https://doi.org/10.1007/s10462-020-09896-5},
	doi = {10.1007/s10462-020-09896-5},
	abstract = {The family of gradient boosting algorithms has been recently extended with several interesting proposals (i.e. XGBoost, LightGBM and CatBoost) that focus on both speed and accuracy. XGBoost is a scalable ensemble technique that has demonstrated to be a reliable and efficient machine learning challenge solver. LightGBM is an accurate model focused on providing extremely fast training performance using selective sampling of high gradient instances. CatBoost modifies the computation of gradients to avoid the prediction shift in order to improve the accuracy of the model. This work proposes a practical analysis of how these novel variants of gradient boosting work in terms of training speed, generalization performance and hyper-parameter setup. In addition, a comprehensive comparison between XGBoost, LightGBM, CatBoost, random forests and gradient boosting has been performed using carefully tuned models as well as using their default settings. The results of this comparison indicate that CatBoost obtains the best results in generalization accuracy and AUC in the studied datasets although the differences are small. LightGBM is the fastest of all methods but not the most accurate. Finally, XGBoost places second both in accuracy and in training speed. Finally an extensive analysis of the effect of hyper-parameter tuning in XGBoost, LightGBM and CatBoost is carried out using two novel proposed tools.},
	language = {en},
	number = {3},
	urldate = {2024-01-28},
	journal = {Artificial Intelligence Review},
	author = {Bentéjac, Candice and Csörgő, Anna and Martínez-Muñoz, Gonzalo},
	month = mar,
	year = {2021},
	keywords = {CatBoost, Ensembles of classifiers, Gradient boosting, LightGBM, Random forest, XGBoost},
	pages = {1937--1967},
	file = {Full Text PDF:/Users/lucian/Zotero/storage/76SSQRNP/Bentéjac et al. - 2021 - A comparative analysis of gradient boosting algori.pdf:application/pdf},
}

@article{cha_comparison_2021,
	title = {Comparison of {Random} {Forest} and {Gradient} {Boosting} {Machine} {Models} for {Predicting} {Demolition} {Waste} {Based} on {Small} {Datasets} and {Categorical} {Variables}},
	volume = {18},
	issn = {1660-4601},
	url = {https://www.mdpi.com/1660-4601/18/16/8530},
	doi = {10.3390/ijerph18168530},
	abstract = {Construction and demolition waste (DW) generation information has been recognized as a tool for providing useful information for waste management. Recently, numerous researchers have actively utilized artiﬁcial intelligence technology to establish accurate waste generation information. This study investigated the development of machine learning predictive models that can achieve predictive performance on small datasets composed of categorical variables. To this end, the random forest (RF) and gradient boosting machine (GBM) algorithms were adopted. To develop the models, 690 building datasets were established using data preprocessing and standardization. Hyperparameter tuning was performed to develop the RF and GBM models. The model performances were evaluated using the leave-one-out cross-validation technique. The study demonstrated that, for small datasets comprising mainly categorical variables, the bagging technique (RF) predictions were more stable and accurate than those of the boosting technique (GBM). However, GBM models demonstrated excellent predictive performance in some DW predictive models. Furthermore, the RF and GBM predictive models demonstrated signiﬁcantly differing performance across different types of DW. Certain RF and GBM models demonstrated relatively low predictive performance. However, the remaining predictive models all demonstrated excellent predictive performance at R2 values {\textgreater} 0.6, and R values {\textgreater} 0.8. Such differences are mainly because of the characteristics of features applied to model development; we expect the application of additional features to improve the performance of the predictive models. The 11 DW predictive models developed in this study will be useful for establishing detailed DW management strategies.},
	language = {en},
	number = {16},
	urldate = {2024-01-28},
	journal = {International Journal of Environmental Research and Public Health},
	author = {Cha, Gi-Wook and Moon, Hyeun-Jun and Kim, Young-Chan},
	month = aug,
	year = {2021},
	pages = {8530},
	file = {Cha et al. - 2021 - Comparison of Random Forest and Gradient Boosting .pdf:/Users/lucian/Zotero/storage/4LNND9S7/Cha et al. - 2021 - Comparison of Random Forest and Gradient Boosting .pdf:application/pdf},
}

@article{ho_random_1998,
	title = {The random subspace method for constructing decision forests},
	volume = {20},
	issn = {1939-3539},
	url = {https://ieeexplore.ieee.org/document/709601},
	doi = {10.1109/34.709601},
	abstract = {Much of previous attention on decision trees focuses on the splitting criteria and optimization of tree sizes. The dilemma between overfitting and achieving maximum accuracy is seldom resolved. A method to construct a decision tree based classifier is proposed that maintains highest accuracy on training data and improves on generalization accuracy as it grows in complexity. The classifier consists of multiple trees constructed systematically by pseudorandomly selecting subsets of components of the feature vector, that is, trees constructed in randomly chosen subspaces. The subspace method is compared to single-tree classifiers and other forest construction methods by experiments on publicly available datasets, where the method's superiority is demonstrated. We also discuss independence between trees in a forest and relate that to the combined classification accuracy.},
	number = {8},
	urldate = {2024-01-28},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Ho, Tin Kam},
	month = aug,
	year = {1998},
	note = {Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence},
	keywords = {Binary trees, Classification tree analysis, Clustering algorithms, Decision trees, Stochastic systems, Support vector machine classification, Support vector machines, Tin, Training data},
	pages = {832--844},
	file = {IEEE Xplore Abstract Record:/Users/lucian/Zotero/storage/KHHN3R9F/709601.html:text/html},
}

@inproceedings{parmar_review_2019,
	address = {Cham},
	series = {Lecture {Notes} on {Data} {Engineering} and {Communications} {Technologies}},
	title = {A {Review} on {Random} {Forest}: {An} {Ensemble} {Classifier}},
	isbn = {978-3-030-03146-6},
	shorttitle = {A {Review} on {Random} {Forest}},
	doi = {10.1007/978-3-030-03146-6_86},
	abstract = {Ensemble classification is an information mining approach which utilizes various classifiers that cooperate for distinguishing the class label for new unlabeled thing from accumulation. Arbitrary Forest approach joins a few randomized choice trees and totals their forecasts by averaging. It has grabbed well-known attention from the community of research because of its high accuracy and superiority which additionally increase the performance. Now in this paper, we take a gander at improvements of Random Forest from history to till date. Our approach is to take a recorded view on the improvement of this prominently effective classification procedure. To begin with history of Random Forest to main technique proposed by Breiman then successful applications that utilized Random Forest and finally some comparison with other classifiers. This paper is proposed to give non specialists simple access to the principle thoughts of random forest.},
	language = {en},
	booktitle = {International {Conference} on {Intelligent} {Data} {Communication} {Technologies} and {Internet} of {Things} ({ICICI}) 2018},
	publisher = {Springer International Publishing},
	author = {Parmar, Aakash and Katariya, Rakesh and Patel, Vatsal},
	editor = {Hemanth, Jude and Fernando, Xavier and Lafata, Pavel and Baig, Zubair},
	year = {2019},
	pages = {758--763},
	file = {Parmar et al. - 2019 - A Review on Random Forest An Ensemble Classifier.pdf:/Users/lucian/Zotero/storage/RIPPHE9J/Parmar et al. - 2019 - A Review on Random Forest An Ensemble Classifier.pdf:application/pdf},
}

@inproceedings{song_random_2015,
	title = {The random forest classifier applied in droplet fingerprint recognition},
	doi = {10.1109/FSKD.2015.7382031},
	author = {Song, Qing and Liu, Xiaoou and Yang, Lu},
	month = aug,
	year = {2015},
	pages = {722--726},
}

@incollection{xanthopoulos_linear_2013,
	address = {New York, NY},
	series = {{SpringerBriefs} in {Optimization}},
	title = {Linear {Discriminant} {Analysis}},
	isbn = {978-1-4419-9878-1},
	url = {https://doi.org/10.1007/978-1-4419-9878-1_4},
	abstract = {In this chapter we discuss another popular data mining algorithm that can be used for supervised or unsupervised learning. Linear Discriminant Analysis (LDA) was proposed by R. Fischer in 1936. It consists in finding the projection hyperplane that minimizes the interclass variance and maximizes the distance between the projected means of the classes. Similarly to PCA, these two objectives can be solved by solving an eigenvalue problem with the corresponding eigenvector defining the hyperplane of interest. This hyperplane can be used for classification, dimensionality reduction and for interpretation of the importance of the given features. In the first part of the chapter we discuss the generic formulation of LDA whereas in the second we present the robust counterpart scheme originally proposed by Kim and Boyd. We also discuss the non linear extension of LDA through the kernel transformation.},
	language = {en},
	urldate = {2024-01-16},
	booktitle = {Robust {Data} {Mining}},
	publisher = {Springer},
	author = {Xanthopoulos, Petros and Pardalos, Panos M. and Trafalis, Theodore B.},
	editor = {Xanthopoulos, Petros and Pardalos, Panos M. and Trafalis, Theodore B.},
	year = {2013},
	doi = {10.1007/978-1-4419-9878-1_4},
	keywords = {Data Mining Algorithm, Feature Space, Kernel Trick, Linear Discriminant Analysis, Robust Counterpart},
	pages = {27--33},
	file = {Xanthopoulos et al. - 2013 - Linear Discriminant Analysis.pdf:/Users/lucian/Zotero/storage/6FD5ZUVZ/Xanthopoulos et al. - 2013 - Linear Discriminant Analysis.pdf:application/pdf},
}

@article{balakrishnama_linear_nodate,
	title = {{LINEAR} {DISCRIMINANT} {ANALYSIS} - {A} {BRIEF} {TUTORIAL}},
	language = {en},
	author = {Balakrishnama, S and Ganapathiraju, A},
	file = {Balakrishnama and Ganapathiraju - LINEAR DISCRIMINANT ANALYSIS - A BRIEF TUTORIAL.pdf:/Users/lucian/Zotero/storage/2HMCJZUL/Balakrishnama and Ganapathiraju - LINEAR DISCRIMINANT ANALYSIS - A BRIEF TUTORIAL.pdf:application/pdf},
}

@misc{cramer_origins_2002,
	address = {Rochester, NY},
	type = {{SSRN} {Scholarly} {Paper}},
	title = {The {Origins} of {Logistic} {Regression}},
	url = {https://papers.ssrn.com/abstract=360300},
	doi = {10.2139/ssrn.360300},
	abstract = {This paper describes the origins of the logistic function, its adoption in bio-assay, and its wider acceptance in statistics. Its roots spread far back to the early 19th century; the survival of the term logistic and the wide application of the device have been determined decisively by the personal histories and individual actions of a few scholars.},
	language = {en},
	urldate = {2024-01-28},
	author = {Cramer, J. S.},
	month = dec,
	year = {2002},
	keywords = {History, Logistic Regression},
	file = {Full Text PDF:/Users/lucian/Zotero/storage/6S7HC68W/Cramer - 2002 - The Origins of Logistic Regression.pdf:application/pdf},
}

@article{xu_validity_2015,
	title = {The validity of the first and second generation {Microsoft} {Kinect}™ for identifying joint center locations during static postures},
	volume = {49},
	issn = {0003-6870},
	url = {https://www.sciencedirect.com/science/article/pii/S0003687015000149},
	doi = {10.1016/j.apergo.2015.01.005},
	abstract = {The Kinect™ sensor released by Microsoft is a low-cost, portable, and marker-less motion tracking system for the video game industry. Since the first generation Kinect sensor was released in 2010, many studies have been conducted to examine the validity of this sensor when used to measure body movement in different research areas. In 2014, Microsoft released the computer-used second generation Kinect sensor with a better resolution for the depth sensor. However, very few studies have performed a direct comparison between all the Kinect sensor-identified joint center locations and their corresponding motion tracking system-identified counterparts, the result of which may provide some insight into the error of the Kinect-identified segment length, joint angles, as well as the feasibility of adapting inverse dynamics to Kinect-identified joint centers. The purpose of the current study is to first propose a method to align the coordinate system of the Kinect sensor with respect to the global coordinate system of a motion tracking system, and then to examine the accuracy of the Kinect sensor-identified coordinates of joint locations during 8 standing and 8 sitting postures of daily activities. The results indicate the proposed alignment method can effectively align the Kinect sensor with respect to the motion tracking system. The accuracy level of the Kinect-identified joint center location is posture-dependent and joint-dependent. For upright standing posture, the average error across all the participants and all Kinect-identified joint centers is 76 mm and 87 mm for the first and second generation Kinect sensor, respectively. In general, standing postures can be identified with better accuracy than sitting postures, and the identification accuracy of the joints of the upper extremities is better than for the lower extremities. This result may provide some information regarding the feasibility of using the Kinect sensor in future studies.},
	urldate = {2024-02-03},
	journal = {Applied Ergonomics},
	author = {Xu, Xu and McGorry, Raymond W.},
	month = jul,
	year = {2015},
	keywords = {Daily activities, Kinect v2, Reference frame alignment},
	pages = {47--54},
	file = {ScienceDirect Snapshot:/Users/lucian/Zotero/storage/4MB7SEB4/S0003687015000149.html:text/html},
}

@inproceedings{cruz_kinect_2012,
	address = {Ouro Preto, Brazil},
	title = {Kinect and {RGBD} {Images}: {Challenges} and {Applications}},
	isbn = {978-0-7695-4830-2 978-1-4673-5091-4},
	shorttitle = {Kinect and {RGBD} {Images}},
	url = {http://ieeexplore.ieee.org/document/6382717/},
	doi = {10.1109/SIBGRAPI-T.2012.13},
	abstract = {Kinect is a device introduced in November 2010 as an accessory of Xbox 360. The acquired data has different and complementary natures, combining geometry with visual attributes. For this reason, Kinect is a ﬂexible tool that can be used in applications from several areas such as: Computer Graphics, Image Processing, Computer Vision and HumanMachine Interaction. In this way, the Kinect is a widely used device in industry (games, robotics, theater performers, natural interfaces, etc.) and in research.},
	language = {en},
	urldate = {2024-02-03},
	booktitle = {2012 25th {SIBGRAPI} {Conference} on {Graphics}, {Patterns} and {Images} {Tutorials}},
	publisher = {IEEE},
	author = {Cruz, Leandro and Lucio, Djalma and Velho, Luiz},
	month = aug,
	year = {2012},
	pages = {36--49},
	file = {Cruz et al. - 2012 - Kinect and RGBD Images Challenges and Application.pdf:/Users/lucian/Zotero/storage/W4348P8K/Cruz et al. - 2012 - Kinect and RGBD Images Challenges and Application.pdf:application/pdf},
}

@article{abbasi_motion_2021,
	title = {A motion capture algorithm based on inertia-{Kinect} sensors for lower body elements and step length estimation},
	volume = {64},
	issn = {1746-8094},
	url = {https://www.sciencedirect.com/science/article/pii/S1746809420304110},
	doi = {10.1016/j.bspc.2020.102290},
	abstract = {Motion capture is a process that movements of living organisms like human or objects are captured and the results are processed for the desired applications. These applications are in rehabilitation, sports, film industry and etc. There are many techniques and instruments for motion capture that optical camera systems are the most accurate ones. But these cameras are high cost and limited to labs. Some sensors like Inertial Measurement Units (IMU) and recently, Kinect cameras have been considered by many researchers because these are low cost and easy to use. But problems like bias, accumulated error and occlusion make them look for improvements. Fusion algorithms are one of the best methods that help to use from each sensor’s strengths. The purpose of this work is design and implementation of an efficient algorithm for estimation of lower limbs joints 3D positions and step length. Orientation quaternions are considered as estimation states. An algorithm was developed with gradient descent and unscented Kalman filter approach based on IMUs and Kinect’s measurements. The IMUs’ data consist of three mutually orthogonal gyroscopes, three mutually orthogonal accelerometers, and a three-axis magnetometer. In this algorithm bias and magnetic distortions have been compensated in parallel structure. The resulted errors have been reported with respect to VICON optical camera system. The results obtained from an experimental test, show up to 60 percent improvement on Kinect in joints 3D positions estimation and the algorithm improves step length estimation error of Kinect from 7.8 cm to 0.03 cm.},
	urldate = {2024-02-03},
	journal = {Biomedical Signal Processing and Control},
	author = {Abbasi, Javad and Salarieh, Hassan and Alasty, Aria},
	month = feb,
	year = {2021},
	keywords = {Data fusion, Gait analysis, Inertial sensor, Kinect, Motion capture, Step length estimation},
	pages = {102290},
	file = {ScienceDirect Snapshot:/Users/lucian/Zotero/storage/XA2JPI4F/S1746809420304110.html:text/html},
}

@article{zheng_cg-recognizer_2022,
	title = {{CG}-{Recognizer}: {A} biosignal-based continuous gesture recognition system},
	volume = {78},
	issn = {1746-8094},
	shorttitle = {{CG}-{Recognizer}},
	url = {https://www.sciencedirect.com/science/article/pii/S1746809422004438},
	doi = {10.1016/j.bspc.2022.103995},
	abstract = {Gesture is a new communication form of human–computer interaction access because of its abundance and diversity. Continuous gesture recognition based on biosignals has gained widespread attention. However, there are two challenges: the movement epenthesis of continuous gestures leads to the deformations of original gestures, and the different signing speeds among various people lead to the diversity of signal length. To solve them, CG-Recognizer: a biosignal-based continuous gesture recognition system is proposed. To the first challenge, gesture signals are transformed into spectrograms, and a feature generator based on a channel-separated convolutional neural network is constructed to extract the spatio-temporal features of gesture signals. For the second challenge, a standard deviation-based signal segmentation algorithm is first proposed to segment signals and label the features of signals. Then, the labeled signal features are sent to the You Only Look Once version 5 (YOLOv5) model for gesture recognition. The experimental results indicate that the mean accuracy of CG-Recognizer is over 94\% on 50 commonly used discrete gestures and over 98\% on 40 continuous gestures composed of the above gestures.},
	urldate = {2024-02-03},
	journal = {Biomedical Signal Processing and Control},
	author = {Zheng, Zhiwen and Wang, Qingshan and Deng, Dazhu and Wang, Qi and Huang, Wei},
	month = sep,
	year = {2022},
	keywords = {Biological signal processing, Continuous gesture recognition, Deep learning, Inertial measurement unit signals, Surface electromyographic signals, Wearable sensors},
	pages = {103995},
}

@inproceedings{gowing_kinect_2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Kinect vs. {Low}-cost {Inertial} {Sensing} for {Gesture} {Recognition}},
	isbn = {978-3-319-04114-8},
	doi = {10.1007/978-3-319-04114-8_41},
	abstract = {In this paper, we investigate efficient recognition of human gestures / movements from multimedia and multimodal data, including the Microsoft Kinect and translational and rotational acceleration and velocity from wearable inertial sensors. We firstly present a system that automatically classifies a large range of activities (17 different gestures) using a random forest decision tree. Our system can achieve near real time recognition by appropriately selecting the sensors that led to the greatest contributing factor for a particular task. Features extracted from multimodal sensor data were used to train and evaluate a customized classifier. This novel technique is capable of successfully classifying various gestures with up to 91 \% overall accuracy on a publicly available data set. Secondly we investigate a wide range of different motion capture modalities and compare their results in terms of gesture recognition accuracy using our proposed approach. We conclude that gesture recognition can be effectively performed by considering an approach that overcomes many of the limitations associated with the Kinect and potentially paves the way for low-cost gesture recognition in unconstrained environments.},
	language = {en},
	booktitle = {{MultiMedia} {Modeling}},
	publisher = {Springer International Publishing},
	author = {Gowing, Marc and Ahmadi, Amin and Destelle, François and Monaghan, David S. and O’Connor, Noel E. and Moran, Kieran},
	editor = {Gurrin, Cathal and Hopfgartner, Frank and Hurst, Wolfgang and Johansen, Håvard and Lee, Hyowon and O’Connor, Noel},
	year = {2014},
	keywords = {Decision tree, Gesture recognition, Inertial sensors, Kinect, Random forest},
	pages = {484--495},
	file = {Full Text PDF:/Users/lucian/Zotero/storage/ESQ4SACI/Gowing et al. - 2014 - Kinect vs. Low-cost Inertial Sensing for Gesture R.pdf:application/pdf},
}

@inproceedings{jais_review_2015,
	address = {Denpasar, Bali, Indonesia},
	title = {A review on gesture recognition using kinect},
	isbn = {978-1-4673-6778-3 978-1-4673-7319-7},
	url = {http://ieeexplore.ieee.org/document/7352569/},
	doi = {10.1109/ICEEI.2015.7352569},
	abstract = {Kinect provides an interesting interaction between user and device with controller-free entertainment environment. It has been used widely in various fields; research, surveillance, medical, entertainment and etc. It is necessary for user to communicate and control a device in natural and efficient way in human-robot interaction based. Hand-controllers and electromechanical device have been used by humans to control robots or machines but there were some constraints in several factors of interaction. As of that, gesture recognition techniques were introduced to overcome those problems. Three sensors in Kinect; an infrared camera, an infrared laser projector and a color camera are used to track and recognize skeletal and human body. In this paper, analysis on gesture recognition in Kinect will be discussed. Several techniques will be compared and the best gesture recognition technique in term of accuracy and efficiency will be chosen in the end of study. At the end of the study, a technique will be proposed to increase the precision of the human gesture recognition using Kinect for better performance in human-robot interaction.},
	language = {en},
	urldate = {2024-02-03},
	booktitle = {2015 {International} {Conference} on {Electrical} {Engineering} and {Informatics} ({ICEEI})},
	publisher = {IEEE},
	author = {Jais, Hairina Mohd and Mahayuddin, Zainal Rasyid and Arshad, Haslina},
	month = aug,
	year = {2015},
	pages = {594--599},
	file = {Jais et al. - 2015 - A review on gesture recognition using kinect.pdf:/Users/lucian/Zotero/storage/N3G4KKDS/Jais et al. - 2015 - A review on gesture recognition using kinect.pdf:application/pdf},
}

@article{acis_classification_2023,
	title = {Classification of human movements by using {Kinect} sensor},
	volume = {81},
	issn = {1746-8094},
	url = {https://www.sciencedirect.com/science/article/pii/S1746809422008710},
	doi = {10.1016/j.bspc.2022.104417},
	abstract = {In recent years, studies have been carried out to classify human movements in many areas such as health and safety. To classify human movements, image processing methods have also started to be used in recent years. With the help of learning-based algorithms, human posture can be defined in the images obtained by various imaging methods. The predecessor methods of these classification algorithms are machine learning and deep learning. In addition, in recent years, the use of sensors that can detect human joints in perceiving human posture has also increased. The Kinect sensor, developed by Microsoft, is one of the most frequently used sensors because it is not wearable and can detect joints with infrared rays and transfer this information directly to the computer via USB connection. This study used a dataset called CAD60 that included real-time human posture information and images obtained using a Microsoft Kinect sensor, which is available in the literature. This dataset contains data that includes different movements/postures of different people. Within the scope of this study, the performances of these algorithms were obtained by using classification algorithms with the MATLAB program and these performances were compared. The classification algorithms have been used to try to improve the results by using different architectures. When raw data is used, classification accuracy is obtained as 72.60\% with one of the machine learning methods, the Cosine K-Nearest Neighbor method. With the feature selection method, this success value has been increased to 74.18\%. In addition, when classified by the Support Vector Machines method after the feature extraction process using the Long Short Term Memory method from the deep network architectures, which is the method proposed in this study, the accuracy rate was increased to 98.95\%. The best method of classifying human posture was investigated by using different methods and a method was proposed by comparing it with the literature.},
	urldate = {2024-02-03},
	journal = {Biomedical Signal Processing and Control},
	author = {Açış, Büşra and Güney, Selda},
	month = mar,
	year = {2023},
	keywords = {Deep learning, Human activity recognition, Kinect sensor, Long short term memory, Machine learning},
	pages = {104417},
	file = {1-s2.0-S1746809422008710-main.pdf:/Users/lucian/Downloads/1-s2.0-S1746809422008710-main.pdf:application/pdf;ScienceDirect Snapshot:/Users/lucian/Zotero/storage/M9MGISDU/S1746809422008710.html:text/html},
}

@inproceedings{saidin_analysis_2020,
	title = {An {Analysis} of {Kinect}-{Based} {Human} {Fall} {Detection} {System}},
	doi = {10.1109/ICSPC50992.2020.9305797},
	author = {Saidin, Nor and Abdul Shukor, Shazmin},
	month = dec,
	year = {2020},
	pages = {220--224},
}

@article{wang_gait_2021,
	title = {A {Gait} {Assessment} {Framework} for {Depression} {Detection} {Using} {Kinect} {Sensors}},
	volume = {21},
	issn = {1558-1748},
	url = {https://ieeexplore.ieee.org/document/9187648},
	doi = {10.1109/JSEN.2020.3022374},
	abstract = {As depression becomes more commonplace in society, the timely and effective detection of the signs of depression for its prevention and early treatment becomes more important. Gait analysis can provide a contactless and low-cost method for depression diagnosis. In this study, we propose a novel gait assessment framework to implement non-intrusive, real-time and automatic depression detection using Kinect, an inexpensive and portable depth sensor. We focus on extracting a novel time-domain and frequency-domain feature (TF-feature) and a spatial geometric feature (SG-feature), and investigating the effectiveness of fused features in detecting depression for the non-contact gait data. A pseudo-velocity model is firstly built to analyze the gait abnormalities of individuals with depression in the time domain. Subsequently, we perform the power spectral density (PSD) analysis on the model to extract the TF-feature. Then, the covariance matrices and the symmetric Stein divergence (S-divergence) are leveraged to obtain the SG-feature, which is fused with TF-feature to form new features for classification. The experimental results on 95 subjects (43 scored-depressed and 52 non-depressed individuals) show that the proposed method achieves a good classification accuracy of 93.75\%, has superior performance compared to several other methods, and significantly alleviates the impact of individual differences. These results indicate the efficacy and robustness of the proposed framework for depression detection.},
	number = {3},
	urldate = {2024-02-03},
	journal = {IEEE Sensors Journal},
	author = {Wang, Tao and Li, Cancheng and Wu, Chunyun and Zhao, Chengjian and Sun, Jieqiong and Peng, Hong and Hu, Xiping and Hu, Bin},
	month = feb,
	year = {2021},
	note = {Conference Name: IEEE Sensors Journal},
	keywords = {Analytical models, covariance matrices, Data mining, depression detection, Feature extraction, Gait, Kinect sensor, Legged locomotion, pseudo-velocity model, Sensors, Skeleton, Three-dimensional displays, time-frequency feature},
	pages = {3260--3270},
	file = {IEEE Xplore Abstract Record:/Users/lucian/Zotero/storage/8IBUXA6C/9187648.html:text/html},
}

@article{mangal_kinect_2020,
	title = {Kinect v2 tracked {Body} {Joint} {Smoothing} for {Kinematic} {Analysis} in {Musculoskeletal} {Disorders}},
	volume = {2020},
	issn = {2694-0604},
	doi = {10.1109/EMBC44109.2020.9175492},
	abstract = {Body joint monitoring is essential for disorder diagnosis and assessment of treatment effectiveness. Microsoft Kinect v2 is a low-cost and markerless human motion-tracking RGB-D sensor that provides spatial locations of tracked skeletal joints in the form of 3D coordinates. Sometimes, body tracking of kinect v2 produces erratic 3D coordinates, which affects the real-time tracking performance of the sensor. A careful study of the literature suggests that skeletal tracking of kinect v2 needs further exploration. This work proposes a filter combined with the concept of body kinematics to remove noise and enhances the quality of 3D coordinates in body frame data. Also, it generates "Motion Signature" of the tracked joint, which shows movement pattern for kinematic analysis, and helpful in joint monitoring of Musculoskeletal Disorders (MSD). The clinically relevant anatomical movement was executed, to evaluate the performance of the proposed filter. We compared Range of Motion (RoM) values obtained from the proposed filter with the gold standard goniometry. Results indicate that RoM values from the proposed filter are in high correlation with the goniometry with an Intraclass Correlation Coefficient values ranging between 0.95 to 0.98 authenticating that it improves the skeletal joint tracking of kinect v2.},
	language = {eng},
	journal = {Annual International Conference of the IEEE Engineering in Medicine and Biology Society. IEEE Engineering in Medicine and Biology Society. Annual International Conference},
	author = {Mangal, Naveen Kumar and Tiwari, Anil Kumar},
	month = jul,
	year = {2020},
	pmid = {33019285},
	keywords = {Biomechanical Phenomena, Humans, Movement, Musculoskeletal Diseases, Range of Motion, Articular, Software},
	pages = {5769--5772},
}

@inproceedings{nehra_unobtrusive_2020,
	title = {Unobtrusive and {Non}-{Invasive} {Human} {Activity} {Recognition} using {Kinect} {Sensor}},
	doi = {10.1109/Indo-TaiwanICAN48429.2020.9181359},
	author = {Nehra, Shalini and Raheja, Jagdish},
	month = feb,
	year = {2020},
	pages = {58--63},
}

@inproceedings{tan_activity_2020,
	title = {Activity {Recognition} {Based} on {DCNN} and {Kinect} {RGB} {Images}},
	doi = {10.1109/iFUZZY50310.2020.9297815},
	author = {Tan, Tan-Hsu and Gochoo, Munkhjargal and Chen, Hong-Syuan and Liu, Shing-Hong and Huang, Yung-Fa},
	month = nov,
	year = {2020},
	pages = {1--4},
}

@article{ren_human_2020,
	title = {Human {Posture} {Recognition} {Using} a {Hybrid} of {Fuzzy} {Logic} and {Machine} {Learning} {Approaches}},
	volume = {PP},
	doi = {10.1109/ACCESS.2020.3011697},
	abstract = {An autonomous assistive robot needs to recognize the body-limb posture of the person being assisted while he/she is lying in a bed to provide care services such as helping change the posture of the person or carrying him/her from the bed to a wheelchair. This paper presents a data-efficient classification of human postures when lying in a bed using a hybrid fuzzy logic and machine learning approach. The classifier was trained using a relatively small dataset containing 19,800 annotated depth images collected using Kinect from 32 test subjects lying in bed. An overall accuracy of 97.1\% was achieved on the dataset. Furthermore, the image dataset including depth and red-green-blue (RGB) images, is available to the research community with the publication of this paper, with the hope that it can benefit other researchers.},
	journal = {IEEE Access},
	author = {Ren, Weiyan and Ma, Ou and Ji, Hongxin and Liu, Xinyuan},
	month = jul,
	year = {2020},
	pages = {1--1},
	file = {Full Text:/Users/lucian/Zotero/storage/MYFRPP5P/Ren et al. - 2020 - Human Posture Recognition Using a Hybrid of Fuzzy .pdf:application/pdf},
}

@article{ince_human_2020,
	title = {Human activity recognition with analysis of angles between skeletal joints using a {RGB}-depth sensor},
	volume = {42},
	issn = {1225-6463},
	url = {https://research.bau.edu.tr/en/publications/human-activity-recognition-with-analysis-of-angles-between-skelet-2},
	doi = {10.4218/etrij.2018-0577},
	language = {English},
	number = {1},
	urldate = {2024-02-03},
	journal = {ETRI Journal},
	author = {İnce, Ömer Faruk and Ince, Ibrahim Furkan and Yıldırım, Mustafa Eren and Park, Jang Sik and Song, Jong Kwan and Yoon, Byung Woo},
	month = feb,
	year = {2020},
	note = {Publisher: John Wiley \& Sons Inc.},
	pages = {78--89},
	file = {Full Text:/Users/lucian/Zotero/storage/C3MC9VA5/İnce et al. - 2020 - Human activity recognition with analysis of angles.pdf:application/pdf;Snapshot:/Users/lucian/Zotero/storage/CYDYETIP/human-activity-recognition-with-analysis-of-angles-between-skelet-2.html:text/html},
}

@article{pisharady_kinect_2013,
	series = {Proceedings of {SPIE} - {The} {International} {Society} for {Optical} {Engineering}},
	title = {Kinect based body posture detection and recognition system: 4th {International} {Conference} on {Graphic} and {Image} {Processing}, {ICGIP} 2012},
	issn = {9780819495662},
	shorttitle = {Kinect based body posture detection and recognition system},
	url = {http://www.scopus.com/inward/record.url?scp=84880152714&partnerID=8YFLogxK},
	doi = {10.1117/12.2009926},
	abstract = {A multi-class human posture detection and recognition algorithm using Kinect based geometric features is presented. The three dimensional skeletal data from the Kinect is converted to a set of angular features. The postures are classified using a support vector machines classifier with polynomial kernel. Detection of posture is done by thresholding the posture probability. The algorithm provided a recognition accuracy of 95.78\% when tested using a 10 class dataset containing 6000 posture samples. The precision and recall rates of the detection system are 100\% and 98.54\% respectively.},
	urldate = {2024-02-03},
	journal = {International Conference on Graphic and Image Processing, ICGIP 2012},
	author = {Pisharady, Pramod Kumar and Saerbeck, Martin},
	month = jul,
	year = {2013},
	keywords = {Angular features, Depth camera, Human-computer interaction, Natural interaction, Posture detection, Posture recognition},
}

@misc{noauthor_human_nodate,
	title = {Human {Posture} {Recognition} {Based} on {Images} {Captured} by the {Kinect} {Sensor} - {Wen}-{June} {Wang}, {Jun}-{Wei} {Chang}, {Shih}-{Fu} {Haung}, {Rong}-{Jyue} {Wang}, 2016},
	url = {https://journals.sagepub.com/doi/10.5772/62163},
	urldate = {2024-02-03},
	file = {Human Posture Recognition Based on Images Captured by the Kinect Sensor - Wen-June Wang, Jun-Wei Chang, Shih-Fu Haung, Rong-Jyue Wang, 2016:/Users/lucian/Zotero/storage/Q2NFDDK9/62163.html:text/html},
}

@article{vishwakarma_three-dimensional_2022,
	title = {Three-dimensional human activity recognition by forming a movement polygon using posture skeletal data from depth sensor},
	volume = {44},
	copyright = {1225-6463/\$ © 2022 ETRI},
	issn = {2233-7326},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.4218/etrij.2020-0101},
	doi = {10.4218/etrij.2020-0101},
	abstract = {Human activity recognition in real time is a challenging task. Recently, a plethora of studies has been proposed using deep learning architectures. The implementation of these architectures requires the high computing power of the machine and a massive database. However, handcrafted features-based machine learning models need less computing power and very accurate where features are effectively extracted. In this study, we propose a handcrafted model based on three-dimensional sequential skeleton data. The human body skeleton movement over a frame is computed through joint positions in a frame. The joints of these skeletal frames are projected into two-dimensional space, forming a “movement polygon.” These polygons are further transformed into a one-dimensional space by computing amplitudes at different angles from the centroid of polygons. The feature vector is formed by the sampling of these amplitudes at different angles. The performance of the algorithm is evaluated using a support vector machine on four public datasets: MSR Action3D, Berkeley MHAD, TST Fall Detection, and NTU-RGB+D, and the highest accuracies achieved on these datasets are 94.13\%, 93.34\%, 95.7\%, and 86.8\%, respectively. These accuracies are compared with similar state-of-the-art and show superior performance.},
	language = {en},
	number = {2},
	urldate = {2024-02-03},
	journal = {ETRI Journal},
	author = {Vishwakarma, Dinesh Kumar and Jain, Konark},
	year = {2022},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.4218/etrij.2020-0101},
	keywords = {feature representation, human action and activity recognition, Kinect sensor, trajectory},
	pages = {286--299},
	file = {Full Text PDF:/Users/lucian/Zotero/storage/ZT64RAZE/Vishwakarma and Jain - 2022 - Three-dimensional human activity recognition by fo.pdf:application/pdf;Snapshot:/Users/lucian/Zotero/storage/MSBBDF3I/etrij.html:text/html},
}

@book{hastie_elements_2009,
	address = {New York, NY},
	series = {Springer {Series} in {Statistics}},
	title = {The {Elements} of {Statistical} {Learning}},
	isbn = {978-0-387-84857-0 978-0-387-84858-7},
	url = {http://link.springer.com/10.1007/978-0-387-84858-7},
	urldate = {2024-02-04},
	publisher = {Springer},
	author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
	year = {2009},
	doi = {10.1007/978-0-387-84858-7},
	keywords = {Averaging, Boosting, classification, clustering, data mining, machine learning, Projection pursuit, Random Forest, supervised learning, Support Vector Machine, unsupervised learning},
	file = {Full Text:/Users/lucian/Zotero/storage/CPHDKDWX/Hastie et al. - 2009 - The Elements of Statistical Learning.pdf:application/pdf},
}

@article{svozil_introduction_1997,
	title = {Introduction to multi-layer feed-forward neural networks},
	volume = {39},
	issn = {0169-7439},
	url = {https://www.sciencedirect.com/science/article/pii/S0169743997000610},
	doi = {10.1016/S0169-7439(97)00061-0},
	abstract = {Basic definitions concerning the multi-layer feed-forward neural networks are given. The back-propagation training algorithm is explained. Partial derivatives of the objective function with respect to the weight and threshold coefficients are derived. These derivatives are valuable for an adaptation process of the considered neural network. Training and generalisation of multi-layer feed-forward neural networks are discussed. Improvements of the standard back-propagation algorithm are reviewed. Example of the use of multi-layer feed-forward neural networks for prediction of carbon-13 NMR chemical shifts of alkanes is given. Further applications of neural networks in chemistry are reviewed. Advantages and disadvantages of multilayer feed-forward neural networks are discussed.},
	number = {1},
	urldate = {2024-02-04},
	journal = {Chemometrics and Intelligent Laboratory Systems},
	author = {Svozil, Daniel and Kvasnicka, Vladimír and Pospichal, Jir̂í},
	month = nov,
	year = {1997},
	keywords = {Back-propagation network, Neural networks},
	pages = {43--62},
	file = {ScienceDirect Snapshot:/Users/lucian/Zotero/storage/D3F5G9PD/S0169743997000610.html:text/html},
}

@ARTICLE{2020SciPy-NMeth,
  author  = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and
            Haberland, Matt and Reddy, Tyler and Cournapeau, David and
            Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and
            Bright, Jonathan and {van der Walt}, St{\'e}fan J. and
            Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and
            Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and
            Kern, Robert and Larson, Eric and Carey, C J and
            Polat, {\.I}lhan and Feng, Yu and Moore, Eric W. and
            {VanderPlas}, Jake and Laxalde, Denis and Perktold, Josef and
            Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and
            Harris, Charles R. and Archibald, Anne M. and
            Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and
            {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  title   = {{{SciPy} 1.0: Fundamental Algorithms for Scientific
            Computing in Python}},
  journal = {Nature Methods},
  year    = {2020},
  volume  = {17},
  pages   = {261--272},
  adsurl  = {https://rdcu.be/b08Wh},
  doi     = {10.1038/s41592-019-0686-2},
}